{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dacon 스타2유저유형 분석",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPqpYI45KS07/34oFxLOXt3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koreahong/statcraft2_analyst/blob/main/Dacon_%EC%8A%A4%ED%83%802%EC%9C%A0%EC%A0%80%EC%9C%A0%ED%98%95_%EB%B6%84%EC%84%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll6EYXkcW366",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d42dcae-f43a-4562-cd52-4cd0e96865a2"
      },
      "source": [
        "#구글 들라이브 연동\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG9FEXL400eT"
      },
      "source": [
        "!pip install bayesian-optimization\n",
        "!pip install pandasql"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPQnyJexZxj7"
      },
      "source": [
        "import pandas as pd                         # 데이터 분석 라이브러리\n",
        "import numpy as np                          # 계산 라이브러리\n",
        "from tqdm import tqdm                       # 진행바\n",
        "from sklearn.metrics import roc_auc_score   # AUC 스코어 계산\n",
        "from sklearn.model_selection import KFold   # K-fold CV    \n",
        "from bayes_opt import BayesianOptimization  # 베이지안 최적화 라이브러리  \n",
        "from functools import partial               # 함수 변수 고정\n",
        "import lightgbm as lgb                      # LightGBM 라이브러리\n",
        "import warnings                             \n",
        "warnings.filterwarnings(\"ignore\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p51cWmgv74-"
      },
      "source": [
        "stardata = pd.read_csv('/content/drive/My Drive/머신러닝_실전예제/Dacon_스타2승자예측/스타2유저유형_data/train.csv' , low_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQxSpJJu-m-Z"
      },
      "source": [
        "def species_converter(string):\n",
        "    if string == 'T':\n",
        "        return 0\n",
        "    elif string == 'P':\n",
        "        return 1\n",
        "    elif string == 'Z':\n",
        "        return 2\n",
        "    else:\n",
        "        raise ValueError\n",
        "\n",
        "def data_preparation(df, answer=False):\n",
        "    game_ids = df['game_id'].unique()\n",
        "    events = ['Ability', 'AddToControlGroup', 'Camera', 'ControlGroup', 'GetControlGroup', 'Right Click', 'Selection', 'SetControlGroup']\n",
        "    unique_event_0, unique_event_1, delta_event = {}, {}, {}\n",
        "    for event in events:\n",
        "        unique_event_0['P0_' + event] = 0\n",
        "        unique_event_1['P1_' + event] = 0\n",
        "        delta_event['delta_' + event] = 0\n",
        "        \n",
        "    species = df.groupby(['game_id', 'player']).species.unique()\n",
        "    event_count = df.groupby(['game_id', 'player']).event.value_counts()\n",
        "    if answer:\n",
        "        winners = df.groupby(['game_id']).winner.max()\n",
        "    \n",
        "    x_data, y_data = [], []\n",
        "    for game_id in tqdm(game_ids):\n",
        "        df_event_count = event_count[game_id].unstack(level=-1)\n",
        "        df = pd.DataFrame(species[game_id])\n",
        "        df = pd.concat([df, df_event_count], axis=1)   \n",
        "        df = df.fillna(0)\n",
        "        \n",
        "        df_P0_species = pd.DataFrame([species_converter(df.loc[0]['species'][0])], columns=['P0_species'])        \n",
        "        df_P1_species = pd.DataFrame([species_converter(df.loc[1]['species'][0])], columns=['P1_species'])\n",
        "        df = df.drop(['species'], axis=1)\n",
        "\n",
        "        df_P0_event = unique_event_0.copy()\n",
        "        for column in df.columns:\n",
        "            df_P0_event['P0_' + column] = df.loc[0][column]\n",
        "        df_P0_event = pd.DataFrame(pd.Series(df_P0_event)).T\n",
        "\n",
        "        df_P1_event = unique_event_1.copy()\n",
        "        for column in df.columns:\n",
        "            df_P1_event['P1_' + column] = df.loc[1][column]\n",
        "        df_P1_event = pd.DataFrame(pd.Series(df_P1_event)).T\n",
        "        \n",
        "        df_delta_event = delta_event.copy()\n",
        "        for column in df.columns:\n",
        "            df_delta_event['delta_' + column] = df_P0_event['P0_' + column][0] - df_P1_event['P1_' + column][0]\n",
        "        df_delta_event = pd.DataFrame(pd.Series(df_delta_event)).T\n",
        "\n",
        "        out = pd.concat([df_P0_species, df_P0_event, df_P1_species, df_P1_event, df_delta_event], axis=1)\n",
        "        out.index = [game_id]\n",
        "        out.index.name = 'game_id'\n",
        "        \n",
        "        x_data.append(out)\n",
        "        if answer:\n",
        "            y_data.append(winners[game_id])  \n",
        "\n",
        "    x_data = pd.concat(x_data)\n",
        "    y_data = np.array(y_data)\n",
        "    \n",
        "    return x_data, y_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMvO-1r2x2wu"
      },
      "source": [
        "x_train, y_train = data_preparation(stardata, answer=True)\n",
        "x_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGL37anaLXqZ"
      },
      "source": [
        "def lgb_cv(num_leaves, learning_rate, n_estimators, subsample, colsample_bytree, reg_alpha, reg_lambda, x_data=None, y_data=None, n_splits=5, output='score'):\n",
        "    score = 0\n",
        "    kf = KFold(n_splits=n_splits)\n",
        "    models = []\n",
        "    for train_index, valid_index in kf.split(x_data):\n",
        "        x_train, y_train = x_data.iloc[train_index], y_data[train_index]\n",
        "        x_valid, y_valid = x_data.iloc[valid_index], y_data[valid_index]\n",
        "        \n",
        "        model = lgb.LGBMClassifier(\n",
        "            num_leaves = int(num_leaves), \n",
        "            learning_rate = learning_rate, \n",
        "            n_estimators = int(n_estimators), \n",
        "            subsample = np.clip(subsample, 0, 1), \n",
        "            colsample_bytree = np.clip(colsample_bytree, 0, 1), \n",
        "            reg_alpha = reg_alpha, \n",
        "            reg_lambda = reg_lambda,\n",
        "        )\n",
        "        \n",
        "        model.fit(x_train, y_train)\n",
        "        models.append(model)\n",
        "        \n",
        "        pred = model.predict_proba(x_valid)[:, 1]\n",
        "        true = y_valid\n",
        "        score += roc_auc_score(true, pred)/n_splits\n",
        "    \n",
        "    if output == 'score':\n",
        "        return score\n",
        "    if output == 'model':\n",
        "        return models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_AVVLeYafqV"
      },
      "source": [
        "# 모델과 관련없는 변수 고정\n",
        "func_fixed = partial(lgb_cv, x_data=x_train, y_data=y_train, n_splits=5, output='score') \n",
        "# 베이지안 최적화 범위 설정\n",
        "lgbBO = BayesianOptimization(\n",
        "    func_fixed, \n",
        "    {\n",
        "        'num_leaves': (16, 1024),        # num_leaves,       범위(16~1024)\n",
        "        'learning_rate': (0.0001, 0.1),  # learning_rate,    범위(0.0001~0.1)\n",
        "        'n_estimators': (16, 1024),      # n_estimators,     범위(16~1024)\n",
        "        'subsample': (0, 1),             # subsample,        범위(0~1)\n",
        "        'colsample_bytree': (0, 1),      # colsample_bytree, 범위(0~1)\n",
        "        'reg_alpha': (0, 10),            # reg_alpha,        범위(0~10)\n",
        "        'reg_lambda': (0, 50),           # reg_lambda,       범위(0~50)\n",
        "    }, \n",
        "    random_state=4321                    # 시드 고정\n",
        ")\n",
        "lgbBO.maximize(init_points=5, n_iter=30) # 처음 5회 랜덤 값으로 score 계산 후 30회 최적화"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoqCyIwuYw4U"
      },
      "source": [
        "params = lgbBO.max['params']\n",
        "models = lgb_cv(\n",
        "    params['num_leaves'], \n",
        "    params['learning_rate'], \n",
        "    params['n_estimators'], \n",
        "    params['subsample'], \n",
        "    params['colsample_bytree'], \n",
        "    params['reg_alpha'], \n",
        "    params['reg_lambda'], \n",
        "    x_data=x_train, y_data=y_train, n_splits=5, output='model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR6REdPAP2dj"
      },
      "source": [
        "test = pd.read_csv('/content/drive/My Drive/머신러닝_실전예제/스타2유저유형_data/test.csv' , low_memory=True)\n",
        "x_test, _ = data_preparation(test, answer=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZR0GYQPajFY"
      },
      "source": [
        "preds = []\n",
        "for model in models:\n",
        "    pred = model.predict_proba(x_test)[:, 1]\n",
        "    preds.append(pred)\n",
        "pred = np.mean(preds, axis=0)\n",
        "\n",
        "submission = pd.read_csv('/content/drive/My Drive/머신러닝_실전예제/스타2유저유형_data/sample_submission.csv', index_col=0)\n",
        "submission['winner'] = submission['winner'] + pred\n",
        "submission.to_csv('/content/drive/My Drive/머신러닝_실전예제/submission/star2_baseline_submission.csv')\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCHWiKwvNVsc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}